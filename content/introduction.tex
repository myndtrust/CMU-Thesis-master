\section{Introduction}

Data centers play a critical role in shaping modern economies and the lives of people around the world. They house information technology (IT) hardware and store data for financial institutions, social media accounts, entertainment and virtual meeting forums amongst many other things. In their physical embodiment, networks of data centers are global scale systems. Within these systems, each data center’s size can be as large as a college campus, and consume 100 times the amount of electrical energy every hour as residential facilities do in a day. Moreover, compared to residential facilities, data centers are subject to bulks of accelerated turnovers in technology. This technology turnover results in the housed IT equipment having a useful life that only spans two to three years. Given their breadth, relative power density, and pivoting use-cases; it is extremely important to develop a comprehensive global level modeling framework to help make data center design decisions that have longevity.
Today there are several metrics, models, and methods available that allow us to assess energy use of data center systems. At the building scale, the most prevalent metric is the data center power usage effectiveness (PUE). PUE couples the IT loads with the building and it indicates the relative efficiency of the building utilities compared to IT workloads. PUE centric designs have indeed had a profound positive impact on data centers' operational energy use. However, some industry insiders have expressed that thinking of PUE in isolation may lead to inadvertently increasing the total cost of ownership for data center systems. Furthermore, researchers have also pointed out the shortfall of PUE even as an operational sustainability indicator; as it does not consider the carbon performance of the energy source.
To fill the isolated view of PUE’s through this research I present an agile model that extends the pioneering works of Whitehead \cite{whitehead15}, Shah \cite{shah11}, and Masanet \cite{CLEER13} from a life cycle perspective. My model provides a holistic life cycle cost of data center systems. The model is composed of four software modules. The first module simulates real world internet traffic profiles for 145K Wikipedia pages. The second module simulates the building energy demands using proven data center building energy and scripting interfaces in a novel way. The third module couples the building energy demands with the marginal costs of energy production for a data center’s respective region. The final module is composed of a hybrid process and economic input-output based life cycle assessment frameworks to assess the embodied costs of the global data center system.
There are two contributions from this work. First, the results of the model affirm that characterising data center costs requires a modular approach. The modular approach must be three tiered. The first tier must characterise the infrastructure in terms of materials and operational processes. In the second tier, the model must be aware of the workload interactions within the system. Then the final tier can allow objective models such as the EIO, marginal costs of energy, and modeling of other forms of costs. The second contribution is shown through the coupling of the network driven workloads and the building energy simulation. I prove the feasibility of inverse cooling plant controls; where the chiller operational point can be kept at a constant load by varying the IT power loads for batch tasks. Opportunistic varying of batch tasks allows over-subscription of workloads when the cooling plant is at theoretical part loads. A similar form of over-subscription has been implemented by IBM and others with consideration of power management.


 
